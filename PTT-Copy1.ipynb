{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#取頁數\n",
    "def get_latest_page(url):\n",
    "    #url = 'https://www.ptt.cc/bbs/Tech_Job/'\n",
    "\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "    #print soup\n",
    "    urlHref = soup.find(class_='btn-group btn-group-paging').find_all('a')[1]['href']#取最新的頁數\n",
    "    pageNumber = re.search('[0-9,]+', urlHref).group()#網址內的數字\n",
    "    #print '現有頁數'+pageNumber\n",
    "\n",
    "    latest_page = []    #存現有網址\n",
    "    latest_page.append(int(pageNumber)+1)\n",
    "    return latest_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#取列表\n",
    "\n",
    "def get_page_list(url):\n",
    "    #url = 'https://www.ptt.cc/bbs/Tech_Job/index1.html'\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "    #print soup\n",
    "\n",
    "    article_list = []\n",
    "    for a in soup.find_all(href=re.compile(\"/bbs/{}/M.\".format(name))):\n",
    "        #https://www.ptt.cc/bbs/Tech_Job/M.1084713143.A.255.html\n",
    "        #print 'https://www.ptt.cc'+str(a['href'])\n",
    "        #print a.text\n",
    "        article_list.append('https://www.ptt.cc'+str(a['href']))\n",
    "    return article_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#取內容\n",
    "\n",
    "def art_cwr(url):\n",
    "    #url='https://www.ptt.cc/bbs/Tech_Job/M.1084713143.A.255.html'\n",
    "\n",
    "    art_dict = {} #資料庫\n",
    "    art_undict = {}#暫存\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    #print soup.find(id='main-content').text\n",
    "    \n",
    "    \n",
    "    art_dict['url'] = url\n",
    "    art_dict['writer'] = soup.find_all(class_=\"article-meta-value\")[0].text\n",
    "    #art_dict['class'] = soup.find_all(class_=\"article-meta-value\")[1].text\n",
    "    art_dict['title'] = soup.find_all(class_=\"article-meta-value\")[2].text\n",
    "    #art_dict['datetime'] = soup.find_all(class_=\"article-meta-value\")[3].text\n",
    "    art_undict['art'] = soup.find(id='main-content').text\n",
    "    art_dict['art'] = art_undict['art'].split()\n",
    "    print soup.find_all(class_=\"article-meta-value\")[2].text\n",
    "    print '完成 : ' + url\n",
    "    return  art_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NCCULawClub  Tech_Job\n",
    "name = 'Tech_Job'\n",
    "url = \"https://www.ptt.cc/bbs/\" + name + \"/index.html\"\n",
    "    \n",
    "#get the latest page number\n",
    "page = get_latest_page(url)[0]\n",
    "#print latestPage\n",
    "\n",
    "##21 2355\n",
    "while (page >2354):#crawl all page end to 0\n",
    "    \n",
    "    \n",
    "    #get page_list\n",
    "    page_list = get_page_list(\"https://www.ptt.cc/bbs/{}/index{}.html\".format(name, page))\n",
    "    #print page_list\n",
    "    \n",
    "    art_dict_lsit = []\n",
    "    json = 0\n",
    "    for links in page_list:\n",
    "        #print links\n",
    "        #art_dict_lsit.append()\n",
    "        json += 1\n",
    "        print art_cwr(links)\n",
    "        f =open('E:/ETL/aaaa/{}.json'.format(json), 'w')\n",
    "        f.write(str(art_cwr(links)))\n",
    "        f.close() \n",
    "        \n",
    "    print '完成 : '+\"https://www.ptt.cc/bbs/{}/index{}.html\\n\".format(name, page)\n",
    "    \n",
    "    \n",
    "    page -= 1\n",
    "    #print art_dict_lsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#讀檔\n",
    "fo = open(\"E:/ETL/aaaa/1.json\", \"r\")\n",
    "str = fo.read();\n",
    "print str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
